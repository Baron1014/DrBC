{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368a38ba-e552-4507-81f8-031cfaa5ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.10.2\n"
     ]
    }
   ],
   "source": [
    "# Import the NetworkX package\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db633216-c0f2-41a1-9eb3-1592e47dd3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wangshihao/Research/SocialNetwork/HW1\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b90d30-aed3-4468-8637-0bddebf35b79",
   "metadata": {},
   "source": [
    "## 1. Read File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "id": "ffc99ef1-337f-42ac-b5af-f3bd9e37c608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1134890, 3])\n",
      "torch.Size([2, 5975248])\n",
      "tensor([[ 0.0000e+00,  1.7194e+01],\n",
      "        [ 1.0000e+00,  1.9914e+01],\n",
      "        [ 2.0000e+00,  1.4682e+01],\n",
      "        ...,\n",
      "        [ 1.1349e+06, -1.8421e+01],\n",
      "        [ 1.1349e+06, -1.8421e+01],\n",
      "        [ 1.1349e+06, -1.8421e+01]])\n"
     ]
    }
   ],
   "source": [
    "class readData():\n",
    "    def __init__(self, data):\n",
    "        self.__bc_value = list()\n",
    "        self.__text = list()\n",
    "        self.__edges = list()\n",
    "        \n",
    "        \n",
    "        if data == \"youtube\":\n",
    "            path1 = f'../data/hw1_data/youtube/com-youtube_score.txt'\n",
    "            path2 = f'../data/hw1_data/youtube/com-youtube.txt'\n",
    "        else:\n",
    "            path1 = f'../data/hw1_data/Synthetic/5000/{data}_score.txt'\n",
    "            path2 = f'../data/hw1_data/Synthetic/5000/{data}.txt'\n",
    "        \n",
    "        # create BC dict\n",
    "        f = open(path1)\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            n, bc = line.split(\":\") if data == \"youtube\" else line.split(\"\\t\")\n",
    "            self.__bc_value.append([int(n), math.log(float(bc)+1e-8)])\n",
    "        f.close()\n",
    "        # read node pair\n",
    "        f = open(path2)\n",
    "        a_list, b_list, Gtext = [], [], []\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            a, b = line.split(\" \") if data == \"youtube\" else line.split(\"\\t\")\n",
    "            a_list.append(int(a))\n",
    "            b_list.append(int(b))\n",
    "            Gtext.append((int(a), int(b)))\n",
    "        self.__edges = [a_list+b_list, b_list+a_list]\n",
    "        f.close()\n",
    "        \n",
    "        # Create an undirected graph G\n",
    "        G = nx.Graph(Gtext)\n",
    "        self.__nodes_list = [[val, 1, 1] for (node, val) in G.degree()]\n",
    "        \n",
    "        \n",
    "    def get_nodes(self):\n",
    "        return torch.Tensor(self.__nodes_list)\n",
    "\n",
    "    def get_edges(self):\n",
    "        return torch.tensor(self.__edges,dtype=torch.long)\n",
    "\n",
    "    def get_bc_value(self):\n",
    "        return torch.Tensor(self.__bc_value)\n",
    "\n",
    "data = readData(\"youtube\")\n",
    "print(data.get_nodes().shape)\n",
    "print(data.get_edges().shape)\n",
    "print(data.get_bc_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b2306-5277-4fb5-a283-c383e7916efc",
   "metadata": {},
   "source": [
    "## 2. Pytorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 776,
   "id": "280e0ffc-3607-4802-b57a-a7f30e6610d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (input): Linear(in_features=3, out_features=128, bias=True)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (conv): GCNConv(128, 128)\n",
      "  (gru): GRU(128, 128, bias=False)\n",
      "  (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "from torch.nn import GRU\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "L = 5\n",
    "    \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.input = Linear(pyg_graph.num_features, 128)\n",
    "        self.relu = torch.nn.LeakyReLU()\n",
    "        self.conv = GCNConv(128, 128)\n",
    "        self.gru = GRU(128, 128, bias=False)\n",
    "        self.linear = Linear(128, 64)\n",
    "        self.output = Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # h1\n",
    "        h1 = self.input(x)\n",
    "        h1 = self.relu(h1)\n",
    "        hi_1 = torch.nn.functional.normalize(h1, p=2, dim=1)\n",
    "        # h2 ~ L\n",
    "        stack_h = hi_1.reshape(1, -1, 128)\n",
    "        for epoch in range(L):\n",
    "            # Caculate Neighbor\n",
    "            h_n = self.conv(hi_1, edge_index)\n",
    "            # GRU Cell\n",
    "            hv = hi_1\n",
    "            hv, _ = self.gru(h_n.reshape(1, *h_n.shape), hv.reshape(1, *hv.shape)) # (input, hidden)\n",
    "            # normalize new hi_1\n",
    "            hi_1 = hv.reshape(-1, 128)\n",
    "            hi_1 = torch.nn.functional.normalize(h1, p=2, dim=1)\n",
    "            # store hidden result\n",
    "            h_cat = torch.cat([stack_h, hi_1.reshape(1, -1, 128)], dim=0)\n",
    "        # z is maximum from all hidden values\n",
    "        z, _ = torch.max(h_cat, 0)\n",
    "        \n",
    "        # decorder\n",
    "        h = self.linear(z)\n",
    "        h = self.relu(h)\n",
    "        out = self.output(h)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "id": "6cc2ed4e-c6d1-458d-814d-8f1a6252722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4992, 3])\n",
      "torch.Size([2, 39398])\n",
      "tensor([-2.5067, -2.5306, -3.4108,  ..., -7.2286, -7.6920, -7.3794])\n",
      "torch.Size([24960, 2])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random \n",
    "import math\n",
    "\n",
    "class Graph():\n",
    "    def __init__(self,batch_size, start=150, end=200, scale=None):\n",
    "        self.graph_list=[]\n",
    "        self.__nodes_list = []\n",
    "        self.__edge_index = []\n",
    "        self.__bc_value = []\n",
    "        self.__sample_pairs = []\n",
    "        \n",
    "        for x in range(batch_size):\n",
    "            if scale is not None:\n",
    "                g = nx.powerlaw_cluster_graph(n=int(scale//batch_size) , m=4, p=0.05, seed=None)\n",
    "            else:\n",
    "                g = nx.powerlaw_cluster_graph(n=random.randint(start,end) , m=4, p=0.05, seed=None)\n",
    "            self.graph_list.append(g)   \n",
    "            \n",
    "        s_list,t_list,en = [],[],0\n",
    "        for g in self.graph_list:\n",
    "            sample_1, sample_2 = [], []\n",
    "            # BC Value\n",
    "            self.__bc_value += list(nx.betweenness_centrality(g).values())\n",
    "            # set nodes\n",
    "            for x in range(g.number_of_nodes()):\n",
    "                self.__nodes_list.append([g.degree[x],1,1])\n",
    "                # sample pair\n",
    "                sample_1 += [x+en for _ in range(5)]\n",
    "                sample_2 += [x+en for _ in range(5)]\n",
    "            random.shuffle(sample_1)\n",
    "            random.shuffle(sample_2)\n",
    "            self.__sample_pairs.extend([[i, j] for i,j in zip(sample_1,sample_2)])\n",
    "\n",
    "            # set edges\n",
    "            for e in g.edges():\n",
    "                s,t = e\n",
    "                s_list.append(s+en)\n",
    "                t_list.append(t+en)\n",
    "            en += g.number_of_nodes()\n",
    "        self.__edge_index=[s_list+t_list,t_list+s_list]\n",
    "        \n",
    "        # log(BC value)\n",
    "        for i, x in enumerate(self.__bc_value):\n",
    "            self.__bc_value[i] = math.log(x+1e-8)\n",
    "            \n",
    "        \n",
    "        \n",
    "    def get_nodes(self):\n",
    "        return torch.Tensor(self.__nodes_list)\n",
    "\n",
    "    def get_edges(self):\n",
    "        return torch.tensor(self.__edge_index,dtype=torch.long)\n",
    "\n",
    "    def get_bc_value(self):\n",
    "        return torch.Tensor(self.__bc_value)\n",
    "        \n",
    "    \n",
    "    def get_pair_index(self):\n",
    "        return torch.tensor(self.__sample_pairs, dtype=torch.long)\n",
    "        \n",
    "\n",
    "\n",
    "g = Graph(16, scale=5000)\n",
    "print(g.get_nodes().shape)\n",
    "print(g.get_edges().shape)\n",
    "print(g.get_bc_value())\n",
    "print(g.get_pair_index().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "id": "4ad39a9f-7116-4e55-b984-2205fb4ce094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "\n",
    "\n",
    "def train(node_start=150, node_end=200, scale=None):\n",
    "    # setting\n",
    "    lr = 0.0001\n",
    "    MAX_ITERATION = 10000\n",
    "    \n",
    "    model = Model()\n",
    "    criterion = torch.nn.CrossEntropyLoss(reduction='sum')  # Define loss criterion.\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    time_list = []\n",
    "    G = Graph(16, start=node_start, end=node_end, scale=scale)\n",
    "    val_G = Graph(16, scale=100)\n",
    "    bc = G.get_bc_value()\n",
    "    wandb.summary[\"scale\"] = G.get_nodes().shape[0]\n",
    "    for epoch in range(MAX_ITERATION):\n",
    "        start = datetime.now()\n",
    "        optimizer.zero_grad() # clear existing gradients\n",
    "        # compute BC ranking score\n",
    "        out= model(G.get_nodes(), G.get_edges())\n",
    "        # compute loss\n",
    "        node_pair = G.get_pair_index()\n",
    "        y_hat = out[node_pair[:, 0]] - out[node_pair[:, 1]]\n",
    "        grad = torch.sigmoid((bc[node_pair[:, 0]] - bc[node_pair[:, 1]]))\n",
    "        #yij, bij = sample_node(y_hat, edges)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, grad.reshape(-1, 1), reduction=\"sum\")\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"[{}/{}] Loss:{:.4f}\".format(epoch, MAX_ITERATION, loss.item()))\n",
    "        loss.backward()\n",
    "        # validation\n",
    "        val_loss = validation(model, val_G)\n",
    "        \n",
    "        wandb.log({\"training_loss\": loss}, step=epoch)\n",
    "        wandb.log({\"val_loss\": val_loss}, step=epoch)\n",
    "        optimizer.step()\n",
    "        end = datetime.now() - start\n",
    "        time_list.append(end)\n",
    "    if scale is not None:\n",
    "        torch.save(model.state_dict(), \"./models/weight_{}.pth\".format(scale))\n",
    "    else:\n",
    "        torch.save(model.state_dict(), \"./models/weight_{}_{}.pth\".format(node_start, node_end))\n",
    "    print(\"Minimum time:{}\".format(min(time_list)))\n",
    "    print(\"Maximum time:{}\".format(max(time_list)))\n",
    "\n",
    "    return model\n",
    "\n",
    "def validation(model, val_G):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        out = model(val_G.get_nodes(), val_G.get_edges())\n",
    "        node_pair = val_G.get_edges().reshape(-1, 2)\n",
    "        y_hat = out[node_pair[:, 0]] - out[node_pair[:, 1]]\n",
    "        bc = val_G.get_bc_value()\n",
    "        grad = torch.sigmoid((bc[node_pair[:, 0]] - bc[node_pair[:, 1]]))\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, grad.reshape(-1, 1), reduction=\"sum\")\n",
    "    \n",
    "    return loss.item()\n",
    "        \n",
    "#model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "id": "6733d142-4b08-414c-a1d9-ff86d23cdf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top-N % accuracy\n",
    "data = readData(0)\n",
    "y_hat = model(data.get_nodes(), data.get_edges())\n",
    "bc_value = data.get_bc_value()\n",
    "predict_values =[[i, *j] for i, j in enumerate(y_hat.tolist())]\n",
    "\n",
    "def topN_accuracy(predict_values ,bc_value, N):\n",
    "    bc_value = sorted(bc_value, key = lambda e:e[1], reverse=True)\n",
    "    predict_values = sorted(predict_values, key = lambda e:e[1], reverse=True)\n",
    "    top_bc, top_predict = [], []\n",
    "    for x in range(len(predict_values)*N//100):\n",
    "        top_bc.append(int(bc_value[x][0]))\n",
    "        top_predict.append(predict_values[x][0])\n",
    "    \n",
    "    return(len(set(top_bc)&set(top_predict)) / len(top_bc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "id": "162159dc-e749-492b-ba15-289bb3353dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau: 0.5074497908521457\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "# Kendall tau\n",
    "data = readData(0)\n",
    "y_hat = model(data.get_nodes(), data.get_edges())\n",
    "bc_value = [ float(j) for i, j in data.get_bc_value()]\n",
    "predict_values =[j[0] for i, j in enumerate(y_hat.tolist())]\n",
    "\n",
    "# compute tau\n",
    "tau, _ = stats.kendalltau(predict_values, bc_value)\n",
    "print(\"Kendall tau: {}\".format(tau))\n",
    "wandb.summary[\"Kendall tau\"] = tau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "dad78337-ba47-47f2-8445-8ef4bcaad42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    for i in range(30):\n",
    "        data = readData(i)\n",
    "        y_hat = model(data.get_nodes(), data.get_edges())\n",
    "        bc_value = data.get_bc_value()\n",
    "        predict_values =[[i, *j] for i, j in enumerate(y_hat.tolist())]\n",
    "        K_bc = [ float(j) for i, j in data.get_bc_value()]\n",
    "        K_predict =[j[0] for i, j in enumerate(y_hat.tolist())]\n",
    "\n",
    "        acc_1, acc_5, acc_10, tau_list = [], [], [], []\n",
    "        acc_1.append(topN_accuracy(predict_values, bc_value, N=1))\n",
    "        acc_5.append(topN_accuracy(predict_values, bc_value, N=5))\n",
    "        acc_10.append(topN_accuracy(predict_values, bc_value, N=10))\n",
    "        tau, _ = stats.kendalltau(K_predict, K_bc)\n",
    "        tau_list.append(tau)\n",
    "    \n",
    "    print(\"Kendall tau: {}\".format(sum(tau_list)/len(tau_list)))\n",
    "    print(\"Top 1 accuracy: {}\".format(sum(acc_1)/len(acc_1)))\n",
    "    print(\"Top 5 accuracy: {}\".format(sum(acc_5)/len(acc_5)))\n",
    "    print(\"Top 10 accuracy: {}\".format(sum(acc_10)/len(acc_10)))\n",
    "    wandb.summary[\"Top 1 accuracy\"]= sum(acc_1)/len(acc_1)\n",
    "    wandb.summary[\"Top 5 accuracy\"]= sum(acc_5)/len(acc_5)\n",
    "    wandb.summary[\"Top 10 accuracy\"]= sum(acc_10)/len(acc_10)\n",
    "    wandb.summary[\"Kendall tau\"] = sum(tau_list)/len(tau_list)\n",
    "\n",
    "def test_scale(model, scale):\n",
    "    data = Graph(16, scale=scale)\n",
    "    y_hat = model(data.get_nodes(), data.get_edges())\n",
    "    bc_value = [[i, j] for i, j in enumerate(data.get_bc_value().tolist())]\n",
    "    predict_values =[[i, *j] for i, j in enumerate(y_hat.tolist())]\n",
    "    K_bc = data.get_bc_value().tolist()\n",
    "    K_predict =[j[0] for i, j in enumerate(y_hat.tolist())]\n",
    "    \n",
    "    acc_1 = topN_accuracy(predict_values, bc_value, N=1)\n",
    "    tau, _ = stats.kendalltau(K_predict, K_bc)\n",
    "    print(\"[{}]Kendall tau: {}\".format(scale, tau))\n",
    "    print(\"[{}]Top 1 accuracy: {}\".format(scale, acc_1))\n",
    "    wandb.summary[\"({}) Top 1 accuracy\".format(scale)]= acc_1\n",
    "    wandb.summary[\"({}) Kendall tau\".format(scale)] = tau\n",
    "\n",
    "def test_youtube(model):\n",
    "    data = readData(\"youtube\")\n",
    "    y_hat = model(data.get_nodes(), data.get_edges())\n",
    "    bc_value = data.get_bc_value()\n",
    "    predict_values =[[i, *j] for i, j in enumerate(y_hat.tolist())]\n",
    "    K_bc = [ float(j) for i, j in data.get_bc_value()]\n",
    "    K_predict =[j[0] for i, j in enumerate(y_hat.tolist())]\n",
    "\n",
    "    acc_1 = topN_accuracy(predict_values, bc_value, N=1)\n",
    "    acc_5 = topN_accuracy(predict_values, bc_value, N=5)\n",
    "    acc_10 = topN_accuracy(predict_values, bc_value, N=10)\n",
    "    tau, _ = stats.kendalltau(K_predict, K_bc)\n",
    "    \n",
    "    print(\"Kendall tau: {}\".format(tau))\n",
    "    print(\"Top 1 accuracy: {}\".format(acc_1))\n",
    "    print(\"Top 5 accuracy: {}\".format(acc_5))\n",
    "    print(\"Top 10 accuracy: {}\".format(acc_10))\n",
    "\n",
    "# test(model)\n",
    "# test_scale(model, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "2d9ca547-629f-4cd4-80a3-a991259a59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment\n",
    "from IPython.display import clear_output\n",
    "    \n",
    "# represent table 6, 7\n",
    "run_list = [\"7_13\", \"13_19\", \"63_76\", \"126_188\", \"251_313\"]\n",
    "scale_list = [5000, 10000, 20000, 50000, 100000]\n",
    "for i in run_list:\n",
    "    clear_output()\n",
    "    s, e = i.split(\"_\")\n",
    "    wandb.init(project='DrBC', entity=\"baron\")\n",
    "    model = train(node_start=int(s), node_end=int(e))\n",
    "    for s in scale_list:\n",
    "        test_scale(model, scale=s)\n",
    "    wandb.finish()\n",
    "    \n",
    "    \n",
    "# represent table 3,4,  \n",
    "run_list = [5000, 10000, 20000, 50000, 100000]\n",
    "\n",
    "for i in run_list:\n",
    "    clear_output()\n",
    "    wandb.init(project='DrBC', entity=\"baron\")\n",
    "    model = train(scale=i)\n",
    "    test(model)\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "id": "6f11897e-5513-446c-8b23-b4b9c4e48b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/wangshihao/Research/SocialNetwork/HW1/wandb/run-20220316_180507-3crc80mv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/baron/DrBC/runs/3crc80mv\" target=\"_blank\">summer-darkness-24</a></strong> to <a href=\"https://wandb.ai/baron/DrBC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]Kendall tau: 0.8309785489908402\n",
      "[5000]Top 1 accuracy: 0.9591836734693877\n",
      "[10000]Kendall tau: 0.8098825854322089\n",
      "[10000]Top 1 accuracy: 0.95\n",
      "[20000]Kendall tau: 0.7842089091090176\n",
      "[20000]Top 1 accuracy: 0.955\n",
      "[50000]Kendall tau: 0.7390498242951619\n",
      "[50000]Top 1 accuracy: 0.944\n",
      "[100000]Kendall tau: 0.706479276031052\n",
      "[100000]Top 1 accuracy: 0.922\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, maxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>(10000) Kendall tau</td><td>0.80988</td></tr><tr><td>(10000) Top 1 accuracy</td><td>0.95</td></tr><tr><td>(100000) Kendall tau</td><td>0.70648</td></tr><tr><td>(100000) Top 1 accuracy</td><td>0.922</td></tr><tr><td>(20000) Kendall tau</td><td>0.78421</td></tr><tr><td>(20000) Top 1 accuracy</td><td>0.955</td></tr><tr><td>(5000) Kendall tau</td><td>0.83098</td></tr><tr><td>(5000) Top 1 accuracy</td><td>0.95918</td></tr><tr><td>(50000) Kendall tau</td><td>0.73905</td></tr><tr><td>(50000) Top 1 accuracy</td><td>0.944</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced <strong style=\"color:#cdcd00\">summer-darkness-24</strong>: <a href=\"https://wandb.ai/baron/DrBC/runs/3crc80mv\" target=\"_blank\">https://wandb.ai/baron/DrBC/runs/3crc80mv</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20220316_180507-3crc80mv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scale_list = [5000, 10000, 20000, 50000, 100000]\n",
    "device = torch.device('cpu')\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"models/weight_13_19.pth\", map_location=device))\n",
    "\n",
    "wandb.init(project='DrBC', entity=\"baron\")\n",
    "#model = train(node_start=13, node_end=19)\n",
    "for s in scale_list:\n",
    "    test_scale(model, scale=s)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298484ce-9376-45d4-a808-9ec0560f80bb",
   "metadata": {},
   "source": [
    "## com-youtube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f7914c-e602-4047-bf46-6e4467d9d370",
   "metadata": {},
   "source": [
    "### Scale 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "id": "c57379ff-a170-4ddd-b42a-413ddd0eff34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau: 0.3330251625212078\n",
      "Top 1 accuracy: 0.47144871342967926\n",
      "Top 5 accuracy: 0.5682362892993091\n",
      "Top 10 accuracy: 0.6246508472186731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangshihao/Library/Python/3.8/lib/python/site-packages/scipy/stats/_stats_py.py:4868: RuntimeWarning: overflow encountered in long_scalars\n",
      "  (2 * xtie * ytie) / m + x0 * y0 / (9 * m * (size - 2)))\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"models/weight_5000.pth\", map_location=device))\n",
    "test_youtube(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1668f58d-57b5-4d4a-830a-10396c0ae073",
   "metadata": {},
   "source": [
    "### Scale 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "44959b58-4428-442b-b9f7-d6276a9afb41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau: 0.33569026812103525\n",
      "Top 1 accuracy: 0.5116320056397603\n",
      "Top 5 accuracy: 0.5210418722684337\n",
      "Top 10 accuracy: 0.5611116495871846\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"models/weight_10000.pth\", map_location=device))\n",
    "test_youtube(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f04dbb8-56be-4cea-b3e3-d08f22be3f3f",
   "metadata": {},
   "source": [
    "### Scale 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 773,
   "id": "9bceb9bb-e146-493c-8565-0d432e2d609e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau: 0.3117399946789241\n",
      "Top 1 accuracy: 0.5685583362707085\n",
      "Top 5 accuracy: 0.5850838855209362\n",
      "Top 10 accuracy: 0.5071152270264079\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"models/weight_20000.pth\", map_location=device))\n",
    "test_youtube(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc03496-5ea7-443a-8ad5-9f6e646e2ae2",
   "metadata": {},
   "source": [
    "### Scale 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "5e051613-42fe-4057-828e-600c1dd9ac84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau: 0.2901170617790284\n",
      "Top 1 accuracy: 0.597726471624956\n",
      "Top 5 accuracy: 0.4899372620893839\n",
      "Top 10 accuracy: 0.4287640211826697\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"models/weight_50000.pth\", map_location=device))\n",
    "test_youtube(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d29a97-4c27-464d-998a-e21bcb694f1a",
   "metadata": {},
   "source": [
    "### Scale 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "id": "3c78530c-fc23-4393-8e93-98f6b70c1639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau: 0.16824677458710227\n",
      "Top 1 accuracy: 0.14125837151921045\n",
      "Top 5 accuracy: 0.19203792471450726\n",
      "Top 10 accuracy: 0.24560089524094847\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"models/weight_100000.pth\", map_location=device))\n",
    "test_youtube(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d625358e-c446-4d86-a833-0aa766795691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
