{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "368a38ba-e552-4507-81f8-031cfaa5ec6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch has version 1.10.2\n"
     ]
    }
   ],
   "source": [
    "# Import the NetworkX package\n",
    "import networkx as nx\n",
    "\n",
    "import torch\n",
    "print(\"PyTorch has version {}\".format(torch.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db633216-c0f2-41a1-9eb3-1592e47dd3a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/wangshihao/Research/SocialNetwork/HW1\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca711379-4a91-42c3-a4f7-c3d5bb88ee1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create BC dict\n",
    "f = open('../data/hw1_data/Synthetic/5000/0_score.txt')\n",
    "bc_dict = dict()\n",
    "for line in f:\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    a, b = line.split(\"\\t\")\n",
    "    bc_dict[int(a)] = float(b)\n",
    "f.close()\n",
    "len(bc_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a458233e-c105-4c4f-a332-2ce23fc7b8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('../data/hw1_data/Synthetic/5000/0.txt')\n",
    "text = []\n",
    "for line in f:\n",
    "    line = line.replace(\"\\n\", \"\")\n",
    "    a, b = line.split(\"\\t\")\n",
    "    text.append((int(a), int(b)))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65aa3787-e5d0-46df-87f9-0ddff60b9bd0",
   "metadata": {},
   "source": [
    "## 1. Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9175e172-0cfb-46c8-a064-e7f471351749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# Create an undirected graph G\n",
    "G = nx.Graph(text)\n",
    "print(G.is_directed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09f37a36-0b69-43f2-9fb9-f3d46463a09a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G has 5000 nodes\n",
      "G has 19982 edges\n"
     ]
    }
   ],
   "source": [
    "# Get number of nodes\n",
    "num_nodes = G.number_of_nodes()\n",
    "print(\"G has {} nodes\".format(num_nodes))\n",
    "\n",
    "# Get number of edges\n",
    "num_edges = G.number_of_edges()\n",
    "print(\"G has {} edges\".format(num_edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b3b83d5-05ec-4e34-9531-385d7107ddf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 1 has degree 178\n"
     ]
    }
   ],
   "source": [
    "node_id = 1\n",
    "\n",
    "# Degree of node 1\n",
    "print(\"Node {} has degree {}\".format(node_id, G.degree[node_id]))\n",
    "\n",
    "# Get neighbor of node 1\n",
    "#for neighbor in G.neighbors(node_id):\n",
    "#    print(\"Node {} has neighbor {}\".format(node_id, neighbor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "35f0865e-4be7-481b-9c17-cdf277806a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': [204, 1, 1], 'y': 0.0888865042991089}"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set x feature\n",
    "dergees = {node:[val, 1, 1] for (node, val) in G.degree()}\n",
    "nx.set_node_attributes(G, dergees, \"x\")\n",
    "nx.set_node_attributes(G, bc_dict, \"y\")\n",
    "G.nodes[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "id": "ffc99ef1-337f-42ac-b5af-f3bd9e37c608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5000, 3])\n",
      "torch.Size([2, 39964])\n",
      "tensor([[ 0.0000e+00, -2.3626e+00],\n",
      "        [ 1.0000e+00, -2.9193e+00],\n",
      "        [ 2.0000e+00, -3.1158e+00],\n",
      "        ...,\n",
      "        [ 4.9970e+03, -1.0842e+01],\n",
      "        [ 4.9980e+03, -9.7114e+00],\n",
      "        [ 4.9990e+03, -9.1234e+00]])\n"
     ]
    }
   ],
   "source": [
    "class readData():\n",
    "    def __init__(self, data):\n",
    "        self.__bc_value = list()\n",
    "        self.__text = list()\n",
    "        self.__edges = list()\n",
    "        \n",
    "        \n",
    "        if data == \"youtube\":\n",
    "            pass\n",
    "        else:\n",
    "            path1 = f'../data/hw1_data/Synthetic/5000/{data}_score.txt'\n",
    "            path2 = f'../data/hw1_data/Synthetic/5000/{data}.txt'\n",
    "        \n",
    "        # create BC dict\n",
    "        f = open(path1)\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            n, bc = line.split(\"\\t\")\n",
    "            self.__bc_value.append([int(n), math.log(float(bc)+1e-8)])\n",
    "        f.close()\n",
    "        \n",
    "        # read node pair\n",
    "        f = open(path2)\n",
    "        a_list, b_list, Gtext = [], [], []\n",
    "        for line in f:\n",
    "            line = line.replace(\"\\n\", \"\")\n",
    "            a, b = line.split(\"\\t\")\n",
    "            a_list.append(int(a))\n",
    "            b_list.append(int(b))\n",
    "            Gtext.append((int(a), int(b)))\n",
    "        self.__edges = [a_list+b_list, b_list+a_list]\n",
    "        f.close()\n",
    "        \n",
    "        # Create an undirected graph G\n",
    "        G = nx.Graph(Gtext)\n",
    "        self.__nodes_list = [[val, 1, 1] for (node, val) in G.degree()]\n",
    "        \n",
    "        \n",
    "    def get_nodes(self):\n",
    "        return torch.Tensor(self.__nodes_list)\n",
    "\n",
    "    def get_edges(self):\n",
    "        return torch.tensor(self.__edges,dtype=torch.long)\n",
    "\n",
    "    def get_bc_value(self):\n",
    "        return torch.Tensor(self.__bc_value)\n",
    "        \n",
    "def read_Data(num):\n",
    "    # create BC dict\n",
    "    f = open(f'../data/hw1_data/Synthetic/5000/{num}_score.txt')\n",
    "    bc_dict = dict()\n",
    "    for line in f:\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        a, b = line.split(\"\\t\")\n",
    "        bc_dict[int(a)] = float(b)\n",
    "    f.close()\n",
    "    len(bc_dict.keys())\n",
    "    \n",
    "    # read node pair\n",
    "    f = open(f'../data/hw1_data/Synthetic/5000/{num}.txt')\n",
    "    text = []\n",
    "    for line in f:\n",
    "        line = line.replace(\"\\n\", \"\")\n",
    "        a, b = line.split(\"\\t\")\n",
    "        text.append((int(a), int(b)))\n",
    "    f.close()\n",
    "    \n",
    "    # Create an undirected graph G\n",
    "    G = nx.Graph(text)\n",
    "    \n",
    "    dergees = {node:[val, 1, 1] for (node, val) in G.degree()}\n",
    "    nx.set_node_attributes(G, dergees, \"x\")\n",
    "    nx.set_node_attributes(G, bc_dict, \"y\")\n",
    "    \n",
    "    return G\n",
    "\n",
    "data = readData(0)\n",
    "print(data.get_nodes().shape)\n",
    "print(data.get_edges().shape)\n",
    "print(data.get_bc_value())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04b2306-5277-4fb5-a283-c383e7916efc",
   "metadata": {},
   "source": [
    "## 2. Pytorch Geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "304e0c6a-5103-4dc3-bf67-504b0c41d6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[5000, 3], edge_index=[2, 39964], y=[5000])\n",
      "tensor([[239,   1,   1],\n",
      "        [196,   1,   1],\n",
      "        [220,   1,   1],\n",
      "        ...,\n",
      "        [  4,   1,   1],\n",
      "        [  4,   1,   1],\n",
      "        [  4,   1,   1]])\n",
      "tensor([9.4175e-02, 7.6438e-02, 9.2790e-02,  ..., 2.8613e-05, 2.5731e-05,\n",
      "        2.0743e-05])\n",
      "tensor([[   0,    0,    0,  ..., 4999, 4999, 4999],\n",
      "        [   1,    2,    3,  ..., 2523, 4508, 4803]])\n",
      "Number of features: 3\n",
      "Data(x=[5000, 3], edge_index=[2, 39964], y=[5000])\n",
      "==============================================================\n",
      "Number of nodes: 5000\n",
      "Number of edges: 39964\n",
      "Average node degree: 15.99\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.utils.convert import from_networkx\n",
    "# Convert the graph into PyTorch geometric\n",
    "pyg_graph = from_networkx(G)\n",
    "print(pyg_graph)\n",
    "print(pyg_graph.x)\n",
    "print(pyg_graph.y)\n",
    "print(pyg_graph.edge_index)\n",
    "print(f'Number of features: {pyg_graph.num_features}')\n",
    "\n",
    "data = pyg_graph  # Get the first graph object.\n",
    "\n",
    "print(data)\n",
    "print('==============================================================')\n",
    "\n",
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {(2*data.num_edges) / data.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49beaa52-d612-4ea8-8e25-f59ecd38026d",
   "metadata": {},
   "source": [
    "## 2.1. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "96f2abe6-1f05-4b38-8172-0ca307beee16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,    1],\n",
      "        [   0,    2],\n",
      "        [   0,    3],\n",
      "        ...,\n",
      "        [4999, 2523],\n",
      "        [4999, 4508],\n",
      "        [4999, 4803]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = data.edge_index\n",
    "print(edge_index.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "280e0ffc-3607-4802-b57a-a7f30e6610d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (input): GCNConv(3, 128)\n",
      "  (relu): LeakyReLU(negative_slope=0.01)\n",
      "  (conv): GCNConv(128, 128)\n",
      "  (gru): GRU(128, 128, bias=False)\n",
      "  (linear): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (output): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn import GRU\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "L = 5\n",
    "    \n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.input = GCNConv(pyg_graph.num_features, 128)\n",
    "        self.relu = torch.nn.LeakyReLU()\n",
    "        self.conv = GCNConv(128, 128)\n",
    "        self.gru = GRU(128, 128, bias=False)\n",
    "        self.linear = Linear(128, 64)\n",
    "        self.output = Linear(64, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # h1\n",
    "        h1 = self.input(x, edge_index)\n",
    "        h1 = self.relu(h1)\n",
    "        hi_1 = torch.nn.functional.normalize(h1, p=2, dim=1)\n",
    "        # h2 ~ L\n",
    "        stack_h = hi_1.reshape(1, -1, 128)\n",
    "        for epoch in range(L):\n",
    "            #for i in range(x.shape[0]):\n",
    "            # Caculate Neighbor\n",
    "            # indices = torch.nonzero(edges[0]==i)\n",
    "            # neighbor_index = edges[1,torch.flatten(indices)]\n",
    "            # n_degree = pyg_graph.x[neighbor_index, 0]\n",
    "            # v_degree = pyg_graph.x[i, 0] #x[i, 0]\n",
    "            # dj = torch.sqrt(n_degree+1)\n",
    "            # dv = torch.sqrt(v_degree+1)\n",
    "            # normal_n = torch.div(hi_1[neighbor_index].reshape(128, -1), dv * dj)\n",
    "            # h_n = torch.sum(normal_n, 1)\n",
    "            h_n = self.conv(hi_1, edge_index)\n",
    "\n",
    "            # GRU Cell\n",
    "            hv = hi_1\n",
    "            hv, _ = self.gru(h_n.reshape(1, *h_n.shape), hv.reshape(1, *hv.shape)) # (input, hidden)\n",
    "            # concat GRU result\n",
    "            # if i == 0:\n",
    "            #     v_cat = hv\n",
    "            # else: \n",
    "            #     v_cat = torch.cat([v_cat, hv], dim=0)\n",
    "\n",
    "            # normalize new hi_1\n",
    "            hi_1 = hv.reshape(-1, 128)\n",
    "            hi_1 = torch.nn.functional.normalize(h1, p=2, dim=1)\n",
    "            # store hidden result\n",
    "            h_cat = torch.cat([stack_h, hi_1.reshape(1, -1, 128)], dim=0)\n",
    "        # z is maximum from all hidden values\n",
    "        z, _ = torch.max(h_cat, 0)\n",
    "        \n",
    "        # decorder\n",
    "        h = self.linear(z)\n",
    "        h = self.relu(h)\n",
    "        out = self.output(h)\n",
    "        \n",
    "        return out\n",
    "\n",
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "id": "b25f0aca-9e16-47b2-8047-82b422569dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[204.,   1.,   1.],\n",
       "        [166.,   1.,   1.],\n",
       "        [205.,   1.,   1.],\n",
       "        ...,\n",
       "        [  4.,   1.,   1.],\n",
       "        [  4.,   1.,   1.],\n",
       "        [  4.,   1.,   1.]])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyg_graph.x.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "id": "1932e1c8-52e6-4a58-a440-e883e2c7ff00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1049],\n",
      "        [-0.1050],\n",
      "        [-0.1049],\n",
      "        ...,\n",
      "        [-0.1053],\n",
      "        [-0.1056],\n",
      "        [-0.1046]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y_hat= model(pyg_graph.x.float(), pyg_graph.edge_index)\n",
    "print(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "id": "1a41a485-2af6-401d-af2d-c375db99a2c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0., grad_fn=<NegBackward0>)"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint \n",
    "\n",
    "def sample_node(y_hat, edge_index, sample_num = 10000):\n",
    "    loss = 0\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    for i in range(sample_num):\n",
    "        idx = randint(0, edge_index.shape[1]-1)\n",
    "        rand_edge = edge_index[:,idx]\n",
    "        # loss\n",
    "        yij = sigmoid(y_hat[rand_edge[0]] - y_hat[rand_edge[1]])\n",
    "        bij = sigmoid(pyg_graph.y[rand_edge[0]] - pyg_graph.y[rand_edge[1]].reshape(1))\n",
    "        if i == 0:\n",
    "            yij_cat = yij\n",
    "            bij_cat = bij\n",
    "        else:\n",
    "            yij_cat = torch.cat((yij_cat, yij))\n",
    "            bij_cat = torch.cat((bij_cat, bij))\n",
    "        #loss += -sigmoid(bij)*torch.log(sigmoid(yij)) - (1-sigmoid(bij))*torch.log(1-sigmoid(yij))\n",
    "    \n",
    "    return yij_cat, bij_cat\n",
    "yij, bij = sample_node(y_hat, edges)\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')\n",
    "loss = criterion(yij.reshape(-1, 1), bij.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "id": "6cc2ed4e-c6d1-458d-814d-8f1a6252722c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2916, 3])\n",
      "torch.Size([2, 22792])\n",
      "tensor([-2.6529, -1.8591, -3.5427,  ..., -6.7344, -7.1018, -7.0028])\n",
      "tensor([[  75,   20],\n",
      "        [ 145,   37],\n",
      "        [  91,   13],\n",
      "        ...,\n",
      "        [2843, 2905],\n",
      "        [2833, 2776],\n",
      "        [2834, 2795]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random \n",
    "import math\n",
    "\n",
    "class Graph():\n",
    "    def __init__(self,batch_size):\n",
    "        self.graph_list=[]\n",
    "        self.__nodes_list = []\n",
    "        self.__edge_index = []\n",
    "        self.__bc_value = []\n",
    "        self.__sample_pairs = []\n",
    "        \n",
    "        for x in range(batch_size):\n",
    "            g = nx.powerlaw_cluster_graph(n=random.randint(150,200) , m=4, p=0.05, seed=None)\n",
    "            self.graph_list.append(g)   \n",
    "        \n",
    "        s_list,t_list,en = [],[],0\n",
    "        for g in self.graph_list:\n",
    "            sample_1, sample_2 = [], []\n",
    "            # BC Value\n",
    "            self.__bc_value += list(nx.betweenness_centrality(g).values())\n",
    "            # set nodes\n",
    "            for x in range(g.number_of_nodes()):\n",
    "                self.__nodes_list.append([g.degree[x],1,1])\n",
    "                # sample pair\n",
    "                sample_1 += [x+en for _ in range(5)]\n",
    "                sample_2 += [x+en for _ in range(5)]\n",
    "            random.shuffle(sample_1)\n",
    "            random.shuffle(sample_2)\n",
    "            self.__sample_pairs.extend([[i, j] for i,j in zip(sample_1,sample_2)])\n",
    "\n",
    "            # set edges\n",
    "            for e in g.edges():\n",
    "                s,t = e\n",
    "                s_list.append(s+en)\n",
    "                t_list.append(t+en)\n",
    "            en += g.number_of_nodes()\n",
    "        self.__edge_index=[s_list+t_list,t_list+s_list]\n",
    "        \n",
    "        # log(BC value)\n",
    "        for i, x in enumerate(self.__bc_value):\n",
    "            self.__bc_value[i] = math.log(x+1e-8)\n",
    "            \n",
    "        \n",
    "        \n",
    "    def get_nodes(self):\n",
    "        return torch.Tensor(self.__nodes_list)\n",
    "\n",
    "    def get_edges(self):\n",
    "        return torch.tensor(self.__edge_index,dtype=torch.long)\n",
    "\n",
    "    def get_bc_value(self):\n",
    "        return torch.Tensor(self.__bc_value)\n",
    "        \n",
    "    \n",
    "    def get_pair_index(self):\n",
    "        return torch.tensor(self.__sample_pairs, dtype=torch.long)\n",
    "        \n",
    "\n",
    "\n",
    "g = Graph(16)\n",
    "print(g.get_nodes().shape)\n",
    "print(g.get_edges().shape)\n",
    "print(g.get_bc_value())\n",
    "print(g.get_pair_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "4ad39a9f-7116-4e55-b984-2205fb4ce094",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/10000] Loss:9630.7988\n",
      "[500/10000] Loss:8297.8584\n",
      "[1000/10000] Loss:7246.6353\n",
      "[1500/10000] Loss:6950.6426\n",
      "[2000/10000] Loss:6965.8389\n",
      "[2500/10000] Loss:6847.7969\n",
      "[3000/10000] Loss:7089.0557\n",
      "[3500/10000] Loss:7134.6812\n",
      "[4000/10000] Loss:6713.6309\n",
      "[4500/10000] Loss:6966.9185\n",
      "[5000/10000] Loss:6991.6953\n",
      "[5500/10000] Loss:7065.4434\n",
      "[6000/10000] Loss:7091.1719\n",
      "[6500/10000] Loss:7124.1362\n",
      "[7000/10000] Loss:6996.0479\n",
      "[7500/10000] Loss:7110.2715\n",
      "[8000/10000] Loss:7077.5571\n",
      "[8500/10000] Loss:7129.0552\n",
      "[9000/10000] Loss:7050.8989\n",
      "[9500/10000] Loss:6918.0205\n"
     ]
    }
   ],
   "source": [
    "# training\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "\n",
    "lr = 0.0001\n",
    "MAX_ITERATION = 10000\n",
    "model = Model()\n",
    "criterion = torch.nn.CrossEntropyLoss(reduction='sum')  # Define loss criterion.\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def train():\n",
    "    time_list = []\n",
    "    for epoch in range(MAX_ITERATION):\n",
    "        start = datetime.now()\n",
    "        optimizer.zero_grad() # clear existing gradients\n",
    "        if epoch % 500 == 0:\n",
    "            G = Graph(16)\n",
    "            bc = G.get_bc_value()\n",
    "        # G = get_training_data()\n",
    "        # pyg_graph = from_networkx(G)\n",
    "        # edges = pyg_graph.edge_index\n",
    "\n",
    "        # compute BC ranking score\n",
    "        out= model(G.get_nodes(), G.get_edges())\n",
    "        # compute loss\n",
    "        node_pair = G.get_pair_index()\n",
    "        y_hat = out[node_pair[:, 0]] - out[node_pair[:, 1]]\n",
    "        grad = torch.sigmoid((bc[node_pair[:, 0]] - bc[node_pair[:, 1]]))\n",
    "        #yij, bij = sample_node(y_hat, edges)\n",
    "        loss = F.binary_cross_entropy_with_logits(y_hat, grad.reshape(-1, 1), reduction=\"sum\")\n",
    "        if epoch % 500 == 0:\n",
    "            print(\"[{}/{}] Loss:{:.4f}\".format(epoch, MAX_ITERATION, loss.item()))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        end = datetime.now() - start\n",
    "        time_list.append(end)\n",
    "        \n",
    "    torch.save(model.state_dict(), \"./models/weight1.pth\")\n",
    "    print(\"Minimum time:{}\".format(min(time_list)))\n",
    "    print(\"Maximum time:{}\".format(max(time_list)))\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 635,
   "id": "6733d142-4b08-414c-a1d9-ff86d23cdf53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 1 accuracy: 0.96\n",
      "Top 5 accuracy: 0.82\n",
      "Top 10 accuracy: 0.804\n"
     ]
    }
   ],
   "source": [
    "# Top-N % accuracy\n",
    "data = readData(0)\n",
    "y_hat = model(data.get_nodes(), data.get_edges())\n",
    "bc_value = data.get_bc_value()\n",
    "predict_values =[[i, *j] for i, j in enumerate(y_hat.tolist())]\n",
    "\n",
    "def topN_accuracy(predict_values ,bc_value, N):\n",
    "    bc_value = sorted(bc_value, key = lambda e:e[1], reverse=True)\n",
    "    predict_values = sorted(predict_values, key = lambda e:e[1], reverse=True)\n",
    "    top_bc, top_predict = [], []\n",
    "    for x in range(len(predict_values)*N//100):\n",
    "        top_bc.append(int(bc_value[x][0]))\n",
    "        top_predict.append(predict_values[x][0])\n",
    "    \n",
    "    return(len(set(top_bc)&set(top_predict)) / len(top_bc))\n",
    "\n",
    "rank = [1, 5, 10]\n",
    "for i in rank:\n",
    "    print(\"Top {} accuracy: {}\".format(i, topN_accuracy(predict_values, bc_value, N=i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "id": "162159dc-e749-492b-ba15-289bb3353dcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kendall tau: 0.5222393696530802\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "# Kendall tau\n",
    "data = readData(0)\n",
    "y_hat = model(data.get_nodes(), data.get_edges())\n",
    "bc_value = [ float(j) for i, j in data.get_bc_value()]\n",
    "predict_values =[j[0] for i, j in enumerate(y_hat.tolist())]\n",
    "\n",
    "# compute tau\n",
    "tau, _ = stats.kendalltau(predict_values, bc_value)\n",
    "print(\"Kendall tau: {}\".format(tau))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9ca547-629f-4cd4-80a3-a991259a59ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
